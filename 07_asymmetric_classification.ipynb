{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/metalmancode/mushroom-classifier/blob/main/07_asymmetric_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# --- STEP 1: LOAD THE LABELED TRAINING DATA ---\n",
        "url_train = \"https://drive.google.com/file/d/1Op1vQftBKN1lrPVGGLJU-UOlv_dScTup/view?usp=sharing\"\n",
        "path_train = \"https://drive.google.com/uc?export=download&id=\" + url_train.split(\"/\")[-2]\n",
        "mushroom_data = pd.read_csv(path_train).set_index('Id')\n",
        "\n",
        "# Define Features (X) and Target (y)\n",
        "X = mushroom_data.drop(columns=['poisonous'])\n",
        "y = mushroom_data['poisonous']\n",
        "\n",
        "# --- STEP 2: BUILD THE CATEGORICAL PIPELINE ---\n",
        "full_pipeline = make_pipeline(\n",
        "    SimpleImputer(strategy='most_frequent'),\n",
        "    OneHotEncoder(handle_unknown='ignore'),\n",
        "    RandomForestClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "# --- STEP 3: FIND THE \"SAFE\" THRESHOLD (ASYMMETRIC TUNING) ---\n",
        "# We use cross-validation to get probabilities for the training set\n",
        "cv_probs = cross_val_predict(full_pipeline, X, y, cv=5, method='predict_proba')\n",
        "pos_probs = cv_probs[:, 1]\n",
        "\n",
        "# Calculate ROC curve to find where Recall is 100%\n",
        "fpr, tpr, thresholds = roc_curve(y, pos_probs)\n",
        "# Find the first threshold that gives us a True Positive Rate (Recall) of 1.0\n",
        "safe_threshold = thresholds[np.argmax(tpr >= 1.0)]\n",
        "\n",
        "print(f\"Safe Threshold found: {safe_threshold}\")\n",
        "\n",
        "# --- STEP 4: TRAIN ON FULL DATA ---\n",
        "full_pipeline.fit(X, y)\n",
        "\n",
        "# --- STEP 5: LOAD AND ALIGN THE FORAGED DATA ---\n",
        "url_foraged = \"https://drive.google.com/file/d/1eWxV9FGj6D-YnMsv4mHMWRcGIKbjrXYL/view?usp=drive_link\"\n",
        "path_foraged = \"https://drive.google.com/uc?export=download&id=\" + url_foraged.split(\"/\")[-2]\n",
        "X_foraged = pd.read_csv(path_foraged).set_index('Id')\n",
        "\n",
        "# FIX: Force X_foraged to have the same columns in the same order as X\n",
        "# This prevents the \"Feature names must match\" ValueError\n",
        "X_foraged = X_foraged[X.columns]\n",
        "\n",
        "# --- STEP 6: PREDICT AND SAVE ---\n",
        "# Get probabilities for the foraged mushrooms\n",
        "foraged_probs = full_pipeline.predict_proba(X_foraged)[:, 1]\n",
        "\n",
        "# Apply the safe threshold: 1 if prob >= threshold, else 0\n",
        "predictions = (foraged_probs >= safe_threshold).astype(int)\n",
        "\n",
        "# Format for the competition app\n",
        "submission = pd.DataFrame({\n",
        "    'Id': X_foraged.index,\n",
        "    'poisonous': predictions\n",
        "})\n",
        "\n",
        "submission.to_csv('mush_submission.csv', index=False)\n",
        "print(\"File 'mush_submission.csv' is ready! üçÑ\")"
      ],
      "metadata": {
        "id": "s6Qgc0XSqieG",
        "outputId": "ad653961-d273-4b58-deda-0466ae918788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Safe Threshold found: 0.01\n",
            "File 'mush_submission.csv' is ready! üçÑ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import recall_score, precision_recall_curve\n",
        "\n",
        "# --- 1. DATA LOADING ---\n",
        "def get_drive_url(url):\n",
        "    return \"https://drive.google.com/uc?export=download&id=\" + url.split(\"/\")[-2]\n",
        "\n",
        "# Training Data\n",
        "url_train = \"https://drive.google.com/file/d/1Op1vQftBKN1lrPVGGLJU-UOlv_dScTup/view?usp=sharing\"\n",
        "df_train = pd.read_csv(get_drive_url(url_train)).set_index('Id')\n",
        "\n",
        "# Competition (Foraged) Data\n",
        "url_foraged = \"https://drive.google.com/file/d/1eWxV9FGj6D-YnMsv4mHMWRcGIKbjrXYL/view?usp=drive_link\"\n",
        "X_foraged_raw = pd.read_csv(get_drive_url(url_foraged)).set_index('Id')\n",
        "\n",
        "# Split features and target\n",
        "X = df_train.drop(columns=['poisonous'])\n",
        "y = df_train['poisonous']\n",
        "\n",
        "# Ensure the foraged data columns match the training data exactly\n",
        "X_foraged = X_foraged_raw[X.columns]\n",
        "\n",
        "# --- 2. PIPELINE & HYPERPARAMETER TUNING ---\n",
        "# We use a pipeline to handle missing values and categorical encoding\n",
        "pipe = make_pipeline(\n",
        "    SimpleImputer(strategy='constant', fill_value='missing'), # Treat '?' as its own info\n",
        "    OneHotEncoder(handle_unknown='ignore'),\n",
        "    RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Search for the best model settings\n",
        "param_grid = {\n",
        "    'randomforestclassifier__n_estimators': [200, 300],\n",
        "    'randomforestclassifier__max_depth': [10, 20, None],\n",
        "    'randomforestclassifier__min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "print(\"Searching for best model parameters...\")\n",
        "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
        "grid.fit(X, y)\n",
        "best_model = grid.best_estimator_\n",
        "print(f\"Best Params: {grid.best_params_}\")\n",
        "\n",
        "# --- 3. OPTIMIZING THE ASYMMETRIC THRESHOLD ---\n",
        "# We need the \"safest\" threshold that still lets us eat as much as possible.\n",
        "# We use cross-validation to get robust probability scores.\n",
        "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "y_probs = cross_val_predict(best_model, X, y, cv=cv, method='predict_proba')[:, 1]\n",
        "\n",
        "# Find the threshold where Recall is 100% (Safety)\n",
        "# precision_recall_curve returns (precision, recall, thresholds)\n",
        "precisions, recalls, thresholds = precision_recall_curve(y, y_probs)\n",
        "\n",
        "# Logic: Find all thresholds where Recall is 1.0, then pick the HIGHEST one\n",
        "# to minimize False Positives (wasted edible mushrooms).\n",
        "safe_thresholds = thresholds[recalls[:-1] == 1.0]\n",
        "if len(safe_thresholds) > 0:\n",
        "    optimal_threshold = np.max(safe_thresholds)\n",
        "else:\n",
        "    optimal_threshold = 0.01 # Ultra-conservative fallback\n",
        "\n",
        "print(f\"Optimal Safety Threshold: {optimal_threshold:.4f}\")\n",
        "\n",
        "# --- 4. FINAL PREDICTION & DEPLOYMENT ---\n",
        "# Final fit on the entire training set\n",
        "best_model.fit(X, y)\n",
        "\n",
        "# Predict probabilities on the competition data\n",
        "final_probs = best_model.predict_proba(X_foraged)[:, 1]\n",
        "\n",
        "# Apply our optimized safety threshold\n",
        "final_preds = (final_probs >= optimal_threshold).astype(int)\n",
        "\n",
        "# Prepare submission\n",
        "submission = pd.DataFrame({\n",
        "    'Id': X_foraged.index,\n",
        "    'poisonous': final_preds\n",
        "})\n",
        "\n",
        "submission.to_csv('optimized_mush_submission.csv', index=False)\n",
        "print(\"Optimization Complete! 'optimized_mush_submission.csv' is ready.\")"
      ],
      "metadata": {
        "id": "RSJcNdYopE1a",
        "outputId": "b9faf689-9c08-4235-de10-f9f019929b60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for best model parameters...\n",
            "Best Params: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__min_samples_leaf': 1, 'randomforestclassifier__n_estimators': 200}\n",
            "Optimal Safety Threshold: 0.0097\n",
            "Optimization Complete! 'optimized_mush_submission.csv' is ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# --- 1. DATA ACQUISITION ---\n",
        "# Helper function to convert a Google Drive file ID into a direct download link.\n",
        "def get_url(drive_id):\n",
        "    return f\"https://drive.google.com/uc?export=download&id={drive_id}\"\n",
        "\n",
        "# Unique IDs for the training set and the unlabeled \"foraged\" (test) set.\n",
        "train_id = \"1Op1vQftBKN1lrPVGGLJU-UOlv_dScTup\"\n",
        "foraged_id = \"1eWxV9FGj6D-YnMsv4mHMWRcGIKbjrXYL\"\n",
        "\n",
        "# Load dataframes and set 'Id' as the index to prevent it from being treated as a feature.\n",
        "df_train = pd.read_csv(get_url(train_id)).set_index('Id')\n",
        "X_foraged_raw = pd.read_csv(get_url(foraged_id)).set_index('Id')\n",
        "\n",
        "# Separate features (X) and target variable (y).\n",
        "X = df_train.drop(columns=['poisonous'])\n",
        "y = df_train['poisonous']\n",
        "\n",
        "# Critical step: Ensure the test set has exactly the same columns in the same order as the training set.\n",
        "X_foraged = X_foraged_raw[X.columns]\n",
        "\n",
        "# --- 2. THE EXPERT PIPELINE ---\n",
        "# We wrap the preprocessing and the model into a single Pipeline object.\n",
        "# This prevents \"data leakage\" and ensures that the test data is treated exactly like the training data.\n",
        "base_pipe = make_pipeline(\n",
        "    # Instead of guessing the mean/mode, we treat 'missing' as a unique category.\n",
        "    # Often, the fact that data is missing is a signal in itself (MNAR - Missing Not At Random).\n",
        "    SimpleImputer(strategy='constant', fill_value='unknown'),\n",
        "\n",
        "    # Convert categorical strings into binary columns (1s and 0s).\n",
        "    # 'handle_unknown=ignore' ensures the model doesn't crash if the test set has a category it hasn't seen before.\n",
        "    OneHotEncoder(handle_unknown='ignore'),\n",
        "\n",
        "    # RandomForest is robust to outliers and non-linear relationships.\n",
        "    RandomForestClassifier(\n",
        "        n_estimators=500,    # Use 500 trees for a stable, \"averaged\" result.\n",
        "        max_depth=15,        # Limit depth to prevent the model from memorizing (overfitting) the training data.\n",
        "        min_samples_leaf=2,  # Require at least 2 samples at a leaf to smooth out predictions.\n",
        "        random_state=42,     # Fixed seed for reproducibility.\n",
        "        n_jobs=-1            # Use all available CPU cores for speed.\n",
        "    )\n",
        ")\n",
        "\n",
        "# --- 3. PROBABILITY CALIBRATION ---\n",
        "# By default, a Random Forest's 'predict_proba' outputs are not true probabilities.\n",
        "# CalibratedClassifierCV adjusts these outputs so that if the model says 70% poisonous,\n",
        "# roughly 70% of those cases actually are poisonous. This is vital for fine-tuning thresholds.\n",
        "print(\"Calibrating model for peak reliability...\")\n",
        "calibrated_model = CalibratedClassifierCV(base_pipe, method='sigmoid', cv=5)\n",
        "calibrated_model.fit(X, y)\n",
        "\n",
        "# --- 4. THRESHOLD OPTIMIZATION (THE \"SURVIVAL\" LOGIC) ---\n",
        "# We use cross-validation to get \"out-of-sample\" probabilities for our training data.\n",
        "# This tells us how the model performs on data it hasn't seen yet.\n",
        "y_probs = cross_val_predict(calibrated_model, X, y, cv=5, method='predict_proba')[:, 1]\n",
        "\n",
        "# Generate a list of precisions and recalls for every possible probability threshold.\n",
        "precisions, recalls, thresholds = precision_recall_curve(y, y_probs)\n",
        "\n",
        "# LOGIC: In mushroom foraging, a False Negative (eating a poisonous mushroom) is fatal.\n",
        "# We want Recall to be 1.0 (100% of poisonous mushrooms are caught).\n",
        "# We search for the 'optimal_threshold' which is the highest probability cutoff that still catches ALL toxins.\n",
        "safe_mask = recalls[:-1] == 1.0\n",
        "if any(safe_mask):\n",
        "    optimal_threshold = thresholds[safe_mask].max()\n",
        "else:\n",
        "    # Fallback: if 100% recall is impossible, we set the threshold to the lowest probability observed.\n",
        "    optimal_threshold = y_probs.min()\n",
        "\n",
        "print(f\"Targeting 100% Recall. Optimal Safety Threshold: {optimal_threshold:.4f}\")\n",
        "\n",
        "# --- 5. GENERATE FINAL COMPETITION SUBMISSION ---\n",
        "# Predict the probability of being 'poisonous' for the new, unknown mushrooms.\n",
        "final_probs = calibrated_model.predict_proba(X_foraged)[:, 1]\n",
        "\n",
        "# Instead of the default 0.5 threshold, we use our 'Optimal Safety Threshold'.\n",
        "# If the probability is even slightly above our \"safe\" limit, we flag it as poisonous (1).\n",
        "final_predictions = (final_probs >= optimal_threshold).astype(int)\n",
        "\n",
        "# Package the results into the format required for competition submission.\n",
        "submission = pd.DataFrame({\n",
        "    'Id': X_foraged.index,\n",
        "    'poisonous': final_predictions\n",
        "})\n",
        "\n",
        "# Save to CSV without the pandas index.\n",
        "submission.to_csv('final_pro_submission.csv', index=False)\n",
        "\n",
        "# Summary for the user to verify the distribution of the results.\n",
        "edible_count = (final_predictions == 0).sum()\n",
        "poison_count = (final_predictions == 1).sum()\n",
        "print(f\"--- RESULTS ---\")\n",
        "print(f\"Mushrooms sorted as Edible: {edible_count}\")\n",
        "print(f\"Mushrooms flagged as Poisonous (Discarded): {poison_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlCgBwBxqmVC",
        "outputId": "097f76a3-0d57-41dd-a5fd-cedc9004d457"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calibrating model for peak reliability...\n",
            "Targeting 100% Recall. Optimal Safety Threshold: 0.0394\n",
            "--- RESULTS ---\n",
            "Mushrooms sorted as Edible: 770\n",
            "Mushrooms flagged as Poisonous (Discarded): 855\n",
            "Check your folder for 'final_pro_submission.csv' and upload it! üçÑ\n"
          ]
        }
      ]
    }
  ]
}